\documentclass[a4paper]{article}

\usepackage{fullpage} % Package to use full page
\usepackage{parskip} % Package to tweak paragraph skipping
\usepackage{amssymb}
\usepackage{tikz} % Package for drawing
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{bm}

\title{Improved Techniques for Training GANs}
\date{}

\begin{document}

\maketitle

\section{Citation}
Salimans, Tim, et al. "Improved techniques for training gans." Advances in Neural Information Processing Systems. 2016.

\begin{verbatim}
http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf
\end{verbatim}

\section{Abstract}
We present techniques to make GANs easier to train. We get state of the art
results on semi-supervised classification on MNIST, SVHN, and CIFAR-10. We also
found that humans struggle to tell generated examples apart from real ones
(21.4\% accuracy on CIFAR-10 images).

\section{Introduction}
In Generative Adversarial Network (GAN), a generator network takes a noise
vector and tries to create a realistic looking example (e.g. an image). A
discriminator tries to identify whether a given input example belongs to the
training set or was generated by the generator. By making these two
networks compete against each other, we reach a Nash equilibrium where
the generator is able to generate realistic examples. In practice, however,
training the GAN to a Nash equilibrium is hard, so we describe improvements to
GANs to make convergence easier.

\section{Related Work}
Our work is inspired by DCGANs, batch normalization, and work that uses GANs
for semi-supervised learning.

\section{Toward Convergent GAN Training}
The discriminator aims to maximize
$J^{(D)}(\bm{\theta}^{(D)}, \bm{\theta}^{(G)})$ w.r.t. $\bm{\theta}^{(D)}$ while
the generator aims to minimize $J^{(G)}(\bm{\theta}^{(D)}, \bm{\theta}^{(G)})$
w.r.t. $\bm{\theta}^{(G)}$. A Nash equilibrium occurs when each player has
minimized their cost function assuming the other player's parameters are fixed.

Our first improvement, called \textbf{feature matching}, pushes the generator to
match the statistics of real data rather than the discriminator output. To do
this, we let $\bm{f}(\bm{x})$ be an intermediate layer of the discriminator. Our
generator's objective function then becomes:

\begin{align}
  || \mathbb{E}_{\bm{x} \sim p_{data}}\bm{f}({\bm{x}})
  - \mathbb{E}_{\bm{z} \sim p_{z}(\bm{z})}{\bm{f}(G(\bm{z}))}||_2^2
\end{align}

Generators have a bad habit of collapsing $\bm{z}$ vectors into a single
example. To fix this, we use \textbf{minibatch discrimination}, which
is when we allow the discriminator to look at a
minibatch of examples (this way, it can tell if the generator keeps producing
the same point). Let $\bm{f}(\bm{x}_i) \in \mathbb{R}^A$ be a vector of
activations from the discriminator. We multiply this by tensor $T \in
\mathbb{R}^{A \times B \times C}$, which results in $M_i \in \mathbb{R}^{
B \times C}$. Then, for an $n$-example minibatch ($i \in \{1...n\}$), we
compute $c_b(\bm{x}_i, \bm{x}_j) = \exp(-|| M_{i, b} - M_{j, b}||_{L_1})
\in \mathbb{R}$. We then compute similarity to other examples as follows:

\begin{align}
  o(\bm{x}_i)_b &= \sum_{j=1}^{n}{c_b(\bm{x}_i, \bm{x}_j)} \in \mathbb{R} \\
  o(\bm{x}_i) &= [o(\bm{x}_i)_1, o(\bm{x}_i)_2, ..., o(\bm{x}_i)_B] \in
    \mathbb{R}^B
\end{align}

We then concatenate $o(\bm{x}_i)$ with $\bm{f}(\bm{x}_i)$ and feed it into
the next layer of the discriminator. The discriminator still produces a label
for each example, but it considers a whole minibatch when making its descision.
Minibatch discrimination generates realistic examples more quickly than
feature matching, but the latter seems to work better when you want to make
a semi-supervised classifier.

We also apply \textbf{historical averaging}, where we update each player's
cost to include $||
\bm{\theta} - \frac{1}{t} \sum_{i=1}^{t}{\bm{\theta}[i]} ||^2$, where
$\bm{\theta}[i]$ is the parameter vector at step $i$.

We also apply \textbf{one-sided label smoothing}, where we replace the 1 label
with $\alpha$ and 0 label with $\beta$. We set $\beta = 0$ so that the model
does not do ridiculous things when it is in an area of space where $p_{data}$
is low.

We also apply \textbf{virtual batch normalization}, where each example is
normalized based on the activations of a reference minibatch. This requires
processing the reference minibatch for each training minibatch, which is
compute-intensive, so we only apply this to the generator.

\section{Assessment of Image Quality}
We use Amazon Mechanical Turk workers get humans to discriminate between real
and generated data. One downside is that human annotators change their
approach (they become more discerning) when you give them feedback. So, as an
alternative, we apply the Inception model to get the label distribution for
each image. We want to make sure our generator generates diverse labels and
that each image's label distribution (as computed by Inception) is low-entropy.
Our metric is $\exp(\mathbb{E}_{\bm{x}}[KL(p(y|\bm{x}) || p(y))])$

\section{Semi-supervised Learning}
To improve a classifier, we add a new class (so we have $K + 1$ classes now)
called the $generated$ class. The probability of this class is $1 - D(\bm{x})$
for all input images in our dataset. We also use the generator to generate
many training examples (about half our dataset is generated examples). Our
loss is then

\begin{align}
  L &= -\mathbb{E}_{\bm{x}, y \sim p_{data}(\bm{x}, y)}[
    \log{p_{model}(y | \bm{x})}
  ] - \mathbb{E}_{\bm{x} \sim G}[
    \log{p_{model}(y = K + 1 | \bm{x})}
  ] \\
  &= L_{supervised} + L_{unsupervised} \\
  L_{supervised} &= -\mathbb{E}_{\bm{x}, y \sim p_{data}(\bm{x}, y)}[
    \log{p_{model}(y | x, y < K + 1)}
  ] \\
  L_{unsupervised} &= -\{
    \mathbb{E}_{\bm{x} \sim p_{data}(\bm{x})}[
      \log(1 - p_{model}(y = K + 1 | \bm{x}))
    ] + \mathbb{E}_{\bm{x} \sim G}[
      \log(p_{model}(y = K + 1 | \bm{x}))
    ]
  \} \\
  &= -\{
    \mathbb{E}_{\bm{x} \sim p_{data}(\bm{x})}[
      \log(D(\bm{x}))
    ] + \mathbb{E}_{\bm{z} \sim noise}[
      \log(1 - D(G(\bm{z})))
    ]
  \}
\end{align}

For the above loss function, we train $G$ with feature matching (minibatch
discrimination does not work at all).

\section{Experiments}
For MNIST, feature matching does not produce visually appealing results, but
it does work better for semi-supervised learning.

For CIFAR-10, we find that we can do better than Mechanical Turk workers.
We find that using the Inception model to pick the best generated images
makes it harder for Mechanical Turk workers to distinguish between real and
generated images.

For ImageNet, our GAN generates furry blobs.

\section{Conclusion}
We propose techniques to stabilize GAN training. More theoretical justification
for what we did here is needed.

\end{document}
